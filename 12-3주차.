##Model Selection 방법론 : 사이킷런의 모듈 중 하나/ 전처리 등 끝내고 마지막에 해볼 수 있는 방법론 
# train_test_split
- random_state 옵션 꼭 설정 (같은값 다시 나오도록)
- 튜플 형태 (변형x) -> 즉, 전처리 끝내고 train_test_split하게됨 
- 학습용데이터, 테스트데이터, 학습데이터 타겟, 테스트 데이터 타겟 순서로 

# 교차검증 
- K-폴드 교차검증 :가장 많이 쓰이고 유명 
                    훈련데이터로 -> 검증 -> 새로운 데이터로 테스트 (이렇게 보통 두번함)
                    보통 20%, 즉 5개 등분으로 쪼갬 
# GridSearchCV :교차검증과 최적하이퍼파라미터 검증(경우의 수 여러번 수행하여 찾)을 한번에
                -> best parameter 가지고 재학습할수도, 그냥 gridsearchcv 결과를 쓸수도 (선택임)



## 앙상블 모델 : 약한 모델 여러개 조합 -> 더 정확한 예측하는 기법
                과적합 방지, 성능은 향상 (왜냐 하나의 모델은 과적합 가능성o)
- 보팅:여러 모델 중 투표 
- 배깅:같은 모델, 다른 데이터 경쟁 ex) 랜덤 포레스트
- 부스팅:가중치 부여하여 이전 모델 오류 계속 수정하는 ex)XGBoost, LightGBM
         성능은 좋지만 과적합 문제o
         *GBM (Gradient Boosting Model) :데이터가 아닌 오차를 훈련시킴 <-> AdaBoost :가중치 수정
#XGBoost 
 -gradient boost 과대적합 방지로 나옴 
 -분류, 회귀 둘다 가능 
 -early step 요정도까지만 학습해줘 할 수 있음 
 -성능은 최고인데, 해석의 문제o
 -sklearn에서는 제공x -> 구글 코랩에서는 설치하면 됨
#LightGBM
 :XGBoost의 성능 좋지만, 여전히 학습시간이 느림 보완위해 등장 
 -learning rate : 강사님은 0.01/ 0.05/ 0.1/ 0.3 로 일단 뒤2개로 빠르게 성능체크하신다고 함 (데이터마다 다름) 
 -코랩에서는 역시 설치 해줘야 
 * 앞에 2개정도 튀는거 어떻게 처리할지 자신이 생각해서 선택해야 -> 모델에 중요하지 않은 변수면 극단적 방법으로 제거한다던가.. 

 *실제 고객에 대응할때는 -> 해석모형 활용함 

 
